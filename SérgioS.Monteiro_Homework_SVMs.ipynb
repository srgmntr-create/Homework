{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "171f9075-b20f-4133-b0d7-2da178ab3f54",
   "metadata": {},
   "source": [
    "# Homework sobre SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392544be-e8b7-449c-b160-6cf6ac7f537d",
   "metadata": {},
   "source": [
    "\n",
    "# Questão 1: Análise Visual de SVMs\n",
    "\n",
    "### a) Quantos erros cada SVM possui no conjunto de treino?\n",
    "\n",
    "Observando as figuras apresentadas no problema:\n",
    "* **LinearSVC (linear kernel)**: 2 erros.\n",
    "* **SVC with linear kernel**: 2 erros.\n",
    "* **SVC with RBF kernel**: 0 erros.\n",
    "* **SVC with polynomial (degree 3) kernel**: 1 erro.\n",
    "\n",
    "---\n",
    "### b) Qual a que lhe parece ser a melhor SVM? Por que?\n",
    "\n",
    "A **SVC with RBF kernel** aparenta ser a melhor SVM.\n",
    "\n",
    "**Motivos**:\n",
    "1.  **Menor Erro de Treino**: Classifica corretamente todos os exemplos de treino, resultando em 0 erros.\n",
    "2.  **Fronteira de Decisão Adequada**: O kernel RBF cria uma fronteira de decisão não-linear que se ajusta bem à distribuição dos dados apresentados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f6697-339e-47f8-88bd-1587ac5fdfa1",
   "metadata": {},
   "source": [
    "# Questão 2: Regularização e Número de Vetores de Suporte\n",
    "\n",
    "Para aumentar o número de vetores de suporte, tornando o modelo mais \"complexo\" quando o número atual de vetores de suporte é relativamente pequeno, você deve **aumentar o parâmetro \"C\"** da classe SVC do scikit-learn.\n",
    "\n",
    "**Explicação**:\n",
    "* O hiperparâmetro `C` é usado para efetuar a regularização do modelo.\n",
    "* Um **`C` baixo** prioriza uma margem maior, geralmente levando a menos vetores de suporte.\n",
    "* Um **`C` alto** penaliza mais as classificações incorretas, resultando em um ajuste mais próximo aos dados de treino e frequentemente a um número maior de vetores de suporte, o que pode ser visto como um modelo mais \"complexo\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4013f722-f882-4e77-890d-aa2a1523186c",
   "metadata": {},
   "source": [
    "# Questão 3: Redução de Custo Computacional SVM Linear para Perceptron\n",
    "\n",
    "Dados: Um classificador usa vetores de entrada com $K=5$ features. Após treinar uma SVM linear, o número de vetores de suporte foi de 450. O cálculo do kernel linear (um produto interno entre dois vetores de dimensão K) requer K multiplicações e K-1 adições. Queremos estimar o fator de redução $F = C_{original}/C_{perceptron}$ no custo computacional durante a fase de teste.\n",
    "\n",
    "---\n",
    "**1. Custo de um Produto Interno (Kernel Linear) para $K=5$**:\n",
    "* Multiplicações: $K = 5$.\n",
    "* Adições: $K-1 = 5-1 = 4$.\n",
    "* Total: $5 + 4 = 9$ operações.\n",
    "\n",
    "**2. Custo da SVM Original ($C_{original}$)**:\n",
    "Para classificar um novo exemplo, a SVM linear calcula o produto interno entre o exemplo de entrada e cada um dos 450 vetores de suporte.\n",
    "* $C_{original} = (\\text{Número de vetores de suporte}) \\times (\\text{Operações por produto interno})$\n",
    "* $C_{original} = 450 \\times 9 = 4050$ operações.\n",
    "\n",
    "**3. Custo do Perceptron ($C_{perceptron}$)**:\n",
    "Quando convertida para um perceptron, a função de decisão é $f(z) = \\langle w, z \\rangle + b$. O cálculo principal é um único produto interno entre o vetor de pesos $w$ (de dimensão $K=5$) e o vetor de entrada $z$.\n",
    "* $C_{perceptron} = (\\text{Operações por produto interno para } K=5)$\n",
    "* $C_{perceptron} = 9$ operações.\n",
    "\n",
    "**4. Fator de Redução ($F$)**:\n",
    "* $F = C_{original} / C_{perceptron}$\n",
    "* $F = 4050 / 9 = 450$.\n",
    "\n",
    "O fator de redução $F$ é **450**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663289db-86b6-4d7f-95ab-0c51e36d3628",
   "metadata": {},
   "source": [
    "# Questão 4: Interpretação do Resultado de Projeto de SVM Linear\n",
    "\n",
    "Os seguintes resultados foram obtidos do treinamento de uma SVM linear usando a classe `SVC` do scikit-learn:\n",
    "* `svm.n_support_ = [1 2]` (número de vetores de suporte por classe).\n",
    "* `svm.support_vectors_ = [[1., 4.], [-2., 3.], [-2., -5.]]` (vetores de suporte $x_0, x_1, x_2$).\n",
    "* `svm.dual_coef_ = [[-0.5, -0.3, 0.8]]` (valores de $\\lambda_n$).\n",
    "* `svc.intercept_ = [-2]` (\"bias\" $b$).\n",
    "---\n",
    "### a) A função de decisão para essa SVM de acordo com a fórmula geral: $f(z)=(\\sum_{n=0}^{N-1}\\lambda_{n}K(z,x_{n}))+b$\n",
    "\n",
    "O kernel é linear, $K(z, x_n) = z \\cdot x_n$.\n",
    "* $x_0 = [1, 4]$, $\\lambda_0 = -0.50$.\n",
    "* $x_1 = [-2, 3]$, $\\lambda_1 = -0.30$.\n",
    "* $x_2 = [-2, -5]$, $\\lambda_2 = 0.80$.\n",
    "* $b = -2.00$.\n",
    "\n",
    "Para $z = [z_1, z_2]$:\n",
    "$f(z) = -0.50 (z \\cdot [1, 4]) - 0.30 (z \\cdot [-2, 3]) + 0.80 (z \\cdot [-2, -5]) - 2.00$\n",
    "$f(z) = -0.50 (1z_1 + 4z_2) - 0.30 (-2z_1 + 3z_2) + 0.80 (-2z_1 - 5z_2) - 2.00$\n",
    "$f(z) = -0.50z_1 - 2.00z_2 + 0.60z_1 - 0.90z_2 - 1.60z_1 - 4.00z_2 - 2.00$\n",
    "$f(z) = (-0.50 + 0.60 - 1.60)z_1 + (-2.00 - 0.90 - 4.00)z_2 - 2.00$\n",
    "$f(z) = -1.50z_1 - 6.90z_2 - 2.00$.\n",
    "\n",
    "---\n",
    "### b) A função de decisão desta SVM quando escrita como um perceptron $f(z)=\\langle z,w \\rangle+b$\n",
    "\n",
    "O vetor de pesos $w = \\sum_{n=0}^{N-1} \\lambda_n x_n$:\n",
    "$w = -0.50 [1, 4] - 0.30 [-2, 3] + 0.80 [-2, -5]$\n",
    "$w = [-0.50, -2.00] + [0.60, -0.90] + [-1.60, -4.00]$\n",
    "$w = [-0.50 + 0.60 - 1.60, -2.00 - 0.90 - 4.00]$\n",
    "$w = [-1.50, -6.90]$.\n",
    "\n",
    "O bias $b = -2.00$.\n",
    "A função de decisão é:\n",
    "$f(z) = [-1.50, -6.90] \\cdot [z_1, z_2] - 2.00$\n",
    "$f(z) = -1.50z_1 - 6.90z_2 - 2.00$.\n",
    "\n",
    "---\n",
    "### c) A saída da função de decisão quando o vetor de entrada é $z=[0,0]$ e o respectivo rótulo predito $y$ assumindo-se que $y=I(f(z)>0)$\n",
    "\n",
    "Para $z = [0, 0]$:\n",
    "$f([0,0]) = -1.50(0) - 6.90(0) - 2.00 = -2.00$.\n",
    "\n",
    "O rótulo predito $y = I(f(z) > 0)$, onde $I(\\cdot)$ é a função \"indicador\", que é 1 se o argumento é verdadeiro, ou 0 caso contrário.\n",
    "$y = I(-2.00 > 0)$\n",
    "Como $-2.00 > 0$ é falso, $y = 0$.\n",
    "\n",
    "**Saída da função de decisão para $z=[0,0]$**: $f([0,0]) = -2.00$.\n",
    "**Rótulo predito $y$ para $z=[0,0]$**: $y = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a48f46-a459-464a-a7fa-065457d9535a",
   "metadata": {},
   "source": [
    "# Questão 5: Interpretação do Resultado de Projeto de SVMs (ak_svm_proval.py)\n",
    "\n",
    "O script `ak_svm_proval.py` e o conjunto de treino `dataset_train.txt` foram usados para gerar uma figura e um log. Quatro SVMs foram treinadas: duas com kernel linear (SVMs 1 e 2) e duas com kernels não-lineares (SVMs 3 e 4). Os resultados e parâmetros dessas SVMs estão detalhados no log fornecido.\n",
    "\n",
    "---\n",
    "### a) Quais as expressões para as SVMs 3 e 4 (não-lineares) e para a SVM 2 (linear) de acordo com a nomenclatura $f(z)=(\\sum_{n=0}^{N-1}\\lambda_{n}K(z,x_{n}))+b$?\n",
    "\n",
    "Usando duas casas decimais para simplificação, com base nos valores do log.\n",
    "\n",
    "**SVM 2 (SVC with linear kernel)**\n",
    "* Vetores de Suporte ($x_n$): $x_0 = [0, -4]$, $x_1 = [-1, 2]$, $x_2 = [-2, -2]$.\n",
    "* Coeficientes Duais ($\\lambda_n = y_n \\alpha_n$): $\\lambda_0 \\approx -0.46$, $\\lambda_1 \\approx -0.28$, $\\lambda_2 \\approx 0.74$.\n",
    "* Bias ($b$): $b \\approx -1.80$.\n",
    "* Kernel: Linear, $K(z, x_n) = z \\cdot x_n$.\n",
    "* Função de decisão $f_2(z)$:\n",
    "    $f_2(z) = -0.46 (z \\cdot [0, -4]) - 0.28 (z \\cdot [-1, 2]) + 0.74 (z \\cdot [-2, -2]) - 1.80$\n",
    "    $f_2(z) = (1.84z_2) + (0.28z_1 - 0.56z_2) + (-1.48z_1 - 1.48z_2) - 1.80$\n",
    "    $f_2(z) = (0.28 - 1.48)z_1 + (1.84 - 0.56 - 1.48)z_2 - 1.80$\n",
    "    $f_2(z) = -1.20z_1 - 0.20z_2 - 1.80$.\n",
    "\n",
    "**SVM 3 (SVC with RBF kernel)**\n",
    "* Vetores de Suporte ($x_n$): $x_0 = [0, -4]$, $x_1 = [-1, 2]$, $x_2 = [3, 3]$, $x_3 = [-5, -6]$, $x_4 = [-4, -5]$, $x_5 = [-2, -2]$.\n",
    "* Coeficientes Duais ($\\lambda_n$): $\\lambda_0 \\approx -0.92, \\lambda_1 \\approx -0.91, \\lambda_2 \\approx -0.91, \\lambda_3 \\approx 0.87, \\lambda_4 \\approx 0.87, \\lambda_5 = 1.00$.\n",
    "* Bias ($b$): $b \\approx -0.09$.\n",
    "* Kernel: RBF, $K(z, x_n) = \\exp(-\\gamma ||z - x_n||^2)$, com $\\gamma = 0.7$.\n",
    "* Função de decisão $f_3(z)$:\n",
    "    $f_3(z) = -0.92 \\exp(-0.7 ||z - [0,-4]||^2) - 0.91 \\exp(-0.7 ||z - [-1,2]||^2) - 0.91 \\exp(-0.7 ||z - [3,3]||^2) + 0.87 \\exp(-0.7 ||z - [-5,-6]||^2) + 0.87 \\exp(-0.7 ||z - [-4,-5]||^2) + 1.00 \\exp(-0.7 ||z - [-2,-2]||^2) - 0.09$.\n",
    "\n",
    "**SVM 4 (SVC with polynomial (degree 3) kernel)**\n",
    "* Vetores de Suporte ($x_n$): $x_0 = [0, -4]$, $x_1 = [-1, 2]$, $x_2 = [-2, -2]$.\n",
    "* Coeficientes Duais ($\\lambda_n$): $\\lambda_0 \\approx -0.01, \\lambda_1 \\approx -0.03, \\lambda_2 \\approx 0.04$.\n",
    "* Bias ($b$): $b \\approx -1.04$.\n",
    "* Kernel: Polinomial, $K(z, x_n) = (\\gamma (z \\cdot x_n) + \\text{coef0})^{\\text{degree}}$. Com `degree`=3, `coef0`=0, `gamma`='auto'. Para 2 features, scikit-learn usa $\\gamma = 1/n_{\\text{features}} = 1/2 = 0.5$ quando `gamma`='auto'.\n",
    "    Assim, $K(z, x_n) = (0.5 (z \\cdot x_n) + 0)^3 = 0.125 (z \\cdot x_n)^3$.\n",
    "* Função de decisão $f_4(z)$:\n",
    "    $f_4(z) = (-0.01 \\cdot 0.125 (z \\cdot [0,-4])^3) - (0.03 \\cdot 0.125 (z \\cdot [-1,2])^3) + (0.04 \\cdot 0.125 (z \\cdot [-2,-2])^3) - 1.04$\n",
    "    $f_4(z) = -0.00125 (-4z_2)^3 - 0.00375 (-z_1+2z_2)^3 + 0.005 (-2z_1-2z_2)^3 - 1.04$.\n",
    "\n",
    "---\n",
    "### b) Quais as expressões para as SVMs 1 e 2 (lineares) quando escritas como perceptrons?\n",
    "\n",
    "O formato perceptron é $f(z) = w \\cdot z + b$.\n",
    "\n",
    "**SVM 1 (LinearSVC)**\n",
    "* Pesos ($w$): $w \\approx [-0.69, -0.11]$.\n",
    "* Bias ($b$): $b \\approx -1.00$.\n",
    "* Função de decisão $f_1(z) = -0.69z_1 - 0.11z_2 - 1.00$.\n",
    "\n",
    "**SVM 2 (SVC with linear kernel)**\n",
    "* Pesos ($w$): $w \\approx [-1.20, -0.20]$.\n",
    "* Bias ($b$): $b \\approx -1.80$.\n",
    "* Função de decisão $f_2(z) = -1.20z_1 - 0.20z_2 - 1.80$.\n",
    "\n",
    "---\n",
    "### c) Suponha que para a SVM 2 (linear), apenas as informações abaixo fossem fornecidas. Explique agora com clareza quais os passos que você adotaria para converter essa SVM linear em um perceptron como descrito no item b) e indique em termos do número de multiplicações e adições, qual economia no custo computacional que a implementação como perceptron alcança.\n",
    "\n",
    "Informações fornecidas para SVM 2:\n",
    "* `svm.n_support_ = [2 1]` (Total 3 SVs).\n",
    "* `svm.support_vectors_ = [[0., -4.], [-1., 2.], [-2., -2.]]` ($x_0, x_1, x_2$).\n",
    "* `svm.dual_coef_ = [[-0.45994152, -0.27992202, 0.73986354]]` ($\\lambda_0, \\lambda_1, \\lambda_2$).\n",
    "* `svc.intercept_ = [-1.79954513]` ($b$).\n",
    "\n",
    "**Passos para conversão**:\n",
    "1.  **Calcular o vetor de pesos $w$**: O vetor de pesos $w$ é dado por $w = \\sum \\lambda_n x_n$.\n",
    "    $w_1 = (-0.45994152 \\cdot 0) + (-0.27992202 \\cdot -1) + (0.73986354 \\cdot -2) \\approx 0 + 0.28 - 1.48 = -1.20$.\n",
    "    $w_2 = (-0.45994152 \\cdot -4) + (-0.27992202 \\cdot 2) + (0.73986354 \\cdot -2) \\approx 1.84 - 0.56 - 1.48 = -0.20$.\n",
    "    Assim, $w \\approx [-1.20, -0.20]$.\n",
    "2.  **Manter o bias $b$**: O bias do perceptron é o mesmo `svc.intercept_` da SVM, $b \\approx -1.80$.\n",
    "3.  **Função de decisão do perceptron**: $f(z) = w \\cdot z + b \\approx -1.20 z_1 - 0.20 z_2 - 1.80$.\n",
    "\n",
    "**Economia no custo computacional (para $K=2$ features)**:\n",
    "Um produto interno $K(z,x_n)$ custa $K$ multiplicações e $K-1$ adições (para $K=2$, são 2 mults, 1 add).\n",
    "* **Custo SVM original (3 SVs)**:\n",
    "    * Kernels: $3 \\times (2 \\text{ mults} + 1 \\text{ add}) = 6 \\text{ mults} + 3 \\text{ adds}$.\n",
    "    * Ponderações ($\\lambda_n \\times \\text{valor do kernel}$): $3 \\text{ mults}$.\n",
    "    * Soma dos termos: $2 \\text{ adds}$.\n",
    "    * Adição do bias: $1 \\text{ add}$.\n",
    "    * Total SVM: $(6+3) = 9 \\text{ mults}, (3+2+1) = 6 \\text{ adds}$. (15 operações).\n",
    "* **Custo Perceptron**:\n",
    "    * Produto interno $w \\cdot z$: $2 \\text{ mults} + 1 \\text{ add}$.\n",
    "    * Adição do bias: $1 \\text{ add}$.\n",
    "    * Total Perceptron: $2 \\text{ mults}, 2 \\text{ adds}$. (4 operações).\n",
    "\n",
    "**Economia**: A implementação como perceptron economiza $9-2=7$ multiplicações e $6-2=4$ adições por classificação. Em termos de operações totais, a forma perceptron é $15/4 \\approx 3.75$ vezes mais rápida.\n",
    "\n",
    "---\n",
    "### d) Para as SVMs 3 e 4 (não-lineares), indique:\n",
    "\n",
    "**SVM 3 (SVC with RBF kernel)**\n",
    "* **d.1) Número total de vetores de suporte (SVs)**: `svm.n_support_ = [3 3]`, Total = $3+3 = \\textbf{6}$.\n",
    "* **d.2) Índices desses SVs no conjunto de treino e os respectivos valores dos \"lambdas\" (coeficientes duais)**:\n",
    "    Índices dos SVs: `svm.support_ = [0 1 2 3 4 5]`.\n",
    "    Valores dos Lambdas ($\\lambda_n = y_n \\alpha_n$): `svm.dual_coef_ = [[-0.91722233 -0.91351914 -0.91300432 0.87185969 0.8718861 1.]]`.\n",
    "    Arredondando: $\\lambda_0 \\approx -0.92, \\lambda_1 \\approx -0.91, \\lambda_2 \\approx -0.91, \\lambda_3 \\approx 0.87, \\lambda_4 \\approx 0.87, \\lambda_5 = 1.00$.\n",
    "* **d.3) Qual o valor do termo independente b chamado de \"bias\" ou \"intercept\"**:\n",
    "    `svc.intercept_ = [-0.08676121]`. $b \\approx \\textbf{-0.09}$.\n",
    "\n",
    "**SVM 4 (SVC with polynomial (degree 3) kernel)**\n",
    "* **d.1) Número total de vetores de suporte (SVs)**: `svm.n_support_ = [2 1]`, Total = $2+1 = \\textbf{3}$.\n",
    "* **d.2) Índices desses SVs no conjunto de treino e os respectivos valores dos \"lambdas\" (coeficientes duais)**:\n",
    "    Índices dos SVs: `svm.support_ = [0 1 5]`.\n",
    "    Valores dos Lambdas ($\\lambda_n = y_n \\alpha_n$): `svm.dual_coef_ = [[-0.00887134 -0.03133903 0.04021037]]`.\n",
    "    Arredondando: $\\lambda_0 \\approx -0.01, \\lambda_1 \\approx -0.03, \\lambda_2 \\approx 0.04$.\n",
    "* **d.3) Qual o valor do termo independente b chamado de \"bias\" ou \"intercept\"**:\n",
    "    `svc.intercept_ = [-1.03731897]`. $b \\approx \\textbf{-1.04}$.\n",
    "\n",
    "---\n",
    "### e) Considerando as saídas da SVM abaixo para o conjunto de treino, em qual dos exemplos de treino esta SVM está menos \"confiante\" (assumindo que esses números são \"confidence scores\") em sua decisão e qual é a classe que esta SVM prediz para este exemplo?\n",
    "\n",
    "Saídas da função de decisão (para SVM 3, conforme log):\n",
    "`svm.decision_function(X)= [-1.00027976, -1.00027976, -0.99977173, 1.00010297, 1.00022828, 0.90993821]`.\n",
    "\n",
    "A confiança da SVM na sua decisão é proporcional ao valor absoluto da saída da função de decisão. Quanto mais próximo de zero for o valor, menos confiante está a SVM.\n",
    "Valores absolutos (aproximados): $1.00, 1.00, 1.00, 1.00, 1.00, 0.91$.\n",
    "O menor valor absoluto é $\\approx 0.91$.\n",
    "\n",
    "* **Exemplo menos confiante**: O sexto exemplo, com $f(z) \\approx 0.91$.\n",
    "* **Classe predita para este exemplo**: Assumindo $y = I(f(z)>0)$ (onde $I(\\cdot)$ é 1 se $f(z)>0$, 0 caso contrário). Como $0.91 > 0$, a classe predita é **1**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d411d-6a1b-4ac8-891d-0797152bc660",
   "metadata": {},
   "source": [
    "## Questão 6: Treinamento de SVM Linear com Scikit-learn\n",
    "\n",
    "Nesta questão, vamos treinar uma Support Vector Machine (SVM) com **kernel linear**. O objetivo é utilizar o hiperparâmetro de regularização $C=1$.\n",
    "\n",
    "Os passos envolvidos são:\n",
    "\n",
    "1.  **Normalização dos Dados:**\n",
    "    * Os dados de treino (`dataset_train.txt`) e teste (`dataset_test.txt`) serão utilizados.\n",
    "    * Os fatores de normalização (média e desvio padrão) serão projetados com base **exclusivamente** no conjunto de treino, para que este conjunto tenha média 0 e variância 1.\n",
    "    * A mesma transformação de normalização será aplicada ao conjunto de teste.\n",
    "\n",
    "2.  **Treinamento da SVM:**\n",
    "    * A SVM será treinada utilizando o conjunto de treino normalizado.\n",
    "\n",
    "3.  **Avaliação do Modelo:**\n",
    "    * O desempenho do modelo SVM treinado será indicado utilizando o conjunto de teste normalizado. Calcularemos a acurácia e exibiremos um relatório de classificação mais detalhado.\n",
    "\n",
    "4.  **Conversão para Perceptron e Análise de Custo Computacional:**\n",
    "    * A SVM linear treinada será conceitualmente convertida para um perceptron (já que uma SVM linear é, em sua forma de predição, um classificador linear $f(z) = w \\cdot z + b$).\n",
    "    * Estimaremos o custo computacional (em termos de número de multiplicações e adições) durante a fase de teste, comparando a SVM em sua forma original (que depende dos vetores de suporte) com sua versão implementada como perceptron.\n",
    "    * Indicaremos se há algum ganho computacional em termos de memória e número de operações ao se converter essa SVM para um perceptron.\n",
    "\n",
    "A seguir, o código Python para realizar estes passos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f975dfc-e2e5-469e-b261-04bdf395f14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Questão 6 ---\n",
      "\n",
      "Dataset de treino carregado com sucesso!\n",
      "  Dimensões de X_train: (6, 2)\n",
      "  Dimensões de y_train: (6,)\n",
      "\n",
      "Dataset de teste carregado com sucesso!\n",
      "  Dimensões de X_test: (4, 2)\n",
      "  Dimensões de y_test: (4,)\n",
      "\n",
      "--- 1. Normalização e Treinamento da SVM ---\n",
      "\n",
      "Dados normalizados.\n",
      "  Dimensões de X_train_normalized: (6, 2)\n",
      "  Dimensões de X_test_normalized: (4, 2)\n",
      "\n",
      "SVM Linear treinada com C=1.\n",
      "  Número de vetores de suporte por classe: [2 2]\n",
      "  Total de vetores de suporte: 4\n",
      "\n",
      "--- 2. Desempenho do Modelo no Conjunto de Teste ---\n",
      "\n",
      "Acurácia da SVM no conjunto de teste normalizado: 1.0000\n",
      "\n",
      "Relatório de Classificação no Teste:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         2\n",
      "         1.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n",
      "\n",
      "--- 3. Conversão para Perceptron e Análise de Custo Computacional ---\n",
      "\n",
      "Análise para K=2 features e N_sv=4 vetores de suporte:\n",
      "\n",
      "Custo da SVM Original (por predição):\n",
      "  Multiplicações: 12\n",
      "  Adições: 8\n",
      "\n",
      "Custo da Versão Perceptron (por predição):\n",
      "  Multiplicações: 2\n",
      "  Adições: 2\n",
      "\n",
      "Ganho Computacional em Operações:\n",
      "  Redução de multiplicações: Fator de ~6.00\n",
      "  Redução de adições: Fator de ~4.00\n",
      "  => Há um ganho em número de operações.\n",
      "\n",
      "Ganho Computacional em Memória (nº de floats):\n",
      "  Memória SVM Original: 13\n",
      "  Memória Perceptron: 3\n",
      "  Redução de memória: Fator de ~4.33\n",
      "  => Há um ganho em memória.\n",
      "\n",
      "--- Fim da Questão 6 ---\n"
     ]
    }
   ],
   "source": [
    "# Célula 8 (Code)\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- Carregamento dos Dados ---\n",
    "# Assumindo que os arquivos 'dataset_train.txt' e 'dataset_test.txt'\n",
    "# estão no mesmo diretório que este script/notebook,\n",
    "# e que os valores são separados por vírgula, com o rótulo na última coluna.\n",
    "\n",
    "print(\"--- Iniciando Questão 6 ---\")\n",
    "\n",
    "try:\n",
    "    # Carregar conjunto de treino\n",
    "    train_data = np.loadtxt('dataset_train.txt', delimiter=',')\n",
    "    X_train = train_data[:, :-1]\n",
    "    y_train = train_data[:, -1]\n",
    "    print(\"\\nDataset de treino carregado com sucesso!\")\n",
    "    print(f\"  Dimensões de X_train: {X_train.shape}\")\n",
    "    print(f\"  Dimensões de y_train: {y_train.shape}\")\n",
    "\n",
    "    # Carregar conjunto de teste\n",
    "    test_data = np.loadtxt('dataset_test.txt', delimiter=',')\n",
    "    X_test = test_data[:, :-1]\n",
    "    y_test = test_data[:, -1]\n",
    "    print(\"\\nDataset de teste carregado com sucesso!\")\n",
    "    print(f\"  Dimensões de X_test: {X_test.shape}\")\n",
    "    print(f\"  Dimensões de y_test: {y_test.shape}\")\n",
    "\n",
    "    # --- 1. Normalização e Treinamento da SVM ---\n",
    "    print(\"\\n--- 1. Normalização e Treinamento da SVM ---\")\n",
    "    # Criar o objeto StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Ajustar o scaler APENAS com os dados de treino e transformar X_train\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Aplicar a MESMA transformação (usando o scaler ajustado no treino) ao X_test\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "    print(\"\\nDados normalizados.\")\n",
    "    print(f\"  Dimensões de X_train_normalized: {X_train_normalized.shape}\")\n",
    "    print(f\"  Dimensões de X_test_normalized: {X_test_normalized.shape}\")\n",
    "\n",
    "    # Treinamento da SVM Linear com C=1\n",
    "    svm_model = SVC(kernel='linear', C=1.0)\n",
    "    svm_model.fit(X_train_normalized, y_train)\n",
    "\n",
    "    print(\"\\nSVM Linear treinada com C=1.\")\n",
    "    print(f\"  Número de vetores de suporte por classe: {svm_model.n_support_}\")\n",
    "    print(f\"  Total de vetores de suporte: {np.sum(svm_model.n_support_)}\")\n",
    "\n",
    "    # --- 2. Desempenho do Modelo no Conjunto de Teste ---\n",
    "    print(\"\\n--- 2. Desempenho do Modelo no Conjunto de Teste ---\")\n",
    "    accuracy_test = svm_model.score(X_test_normalized, y_test)\n",
    "    print(f\"\\nAcurácia da SVM no conjunto de teste normalizado: {accuracy_test:.4f}\")\n",
    "\n",
    "    y_pred_test = svm_model.predict(X_test_normalized)\n",
    "    print(\"\\nRelatório de Classificação no Teste:\")\n",
    "    print(classification_report(y_test, y_pred_test, zero_division=0))\n",
    "\n",
    "    # --- 3. Conversão para Perceptron e Análise de Custo Computacional ---\n",
    "    print(\"\\n--- 3. Conversão para Perceptron e Análise de Custo Computacional ---\")\n",
    "\n",
    "    # Parâmetros do perceptron equivalente\n",
    "    w_perceptron = svm_model.coef_[0]\n",
    "    b_perceptron = svm_model.intercept_[0]\n",
    "\n",
    "    # K: número de features\n",
    "    K = X_train_normalized.shape[1]\n",
    "    # N_sv: número total de vetores de suporte\n",
    "    N_sv = svm_model.support_vectors_.shape[0]\n",
    "\n",
    "    print(f\"\\nAnálise para K={K} features e N_sv={N_sv} vetores de suporte:\")\n",
    "\n",
    "    # Custo da SVM Original (forma com vetores de suporte) na fase de teste\n",
    "    mult_svm_kernels = N_sv * K\n",
    "    add_svm_kernels = N_sv * (K - 1) if K > 0 else 0\n",
    "    mult_svm_duals = N_sv\n",
    "    add_svm_sum = (N_sv - 1) if N_sv > 0 else 0\n",
    "    add_svm_bias = 1\n",
    "\n",
    "    total_mult_svm = mult_svm_kernels + mult_svm_duals\n",
    "    total_add_svm = add_svm_kernels + add_svm_sum + add_svm_bias\n",
    "\n",
    "    print(\"\\nCusto da SVM Original (por predição):\")\n",
    "    print(f\"  Multiplicações: {total_mult_svm}\")\n",
    "    print(f\"  Adições: {total_add_svm}\")\n",
    "\n",
    "    # Custo da versão Perceptron (w . z + b) na fase de teste\n",
    "    mult_perceptron = K\n",
    "    add_perceptron_dot = (K - 1) if K > 0 else 0\n",
    "    add_perceptron_bias = 1\n",
    "    total_add_perceptron = add_perceptron_dot + add_perceptron_bias\n",
    "\n",
    "    print(\"\\nCusto da Versão Perceptron (por predição):\")\n",
    "    print(f\"  Multiplicações: {mult_perceptron}\")\n",
    "    print(f\"  Adições: {total_add_perceptron}\")\n",
    "\n",
    "    print(\"\\nGanho Computacional em Operações:\")\n",
    "    if N_sv > 0 and mult_perceptron > 0 and total_add_perceptron > 0:\n",
    "        if total_mult_svm > mult_perceptron or total_add_svm > total_add_perceptron:\n",
    "            print(f\"  Redução de multiplicações: Fator de ~{total_mult_svm / mult_perceptron:.2f}\")\n",
    "            print(f\"  Redução de adições: Fator de ~{total_add_svm / total_add_perceptron:.2f}\")\n",
    "            print(\"  => Há um ganho em número de operações.\")\n",
    "        else:\n",
    "            print(\"  => O custo de operações é similar ou o perceptron não oferece redução (caso atípico para N_sv > 0).\")\n",
    "    elif N_sv == 0:\n",
    "        print(\"  => Não há vetores de suporte; análise de ganho não aplicável.\")\n",
    "    else:\n",
    "        print(\"  => Não foi possível calcular o fator de redução de operações (divisão por zero evitada ou K=0).\")\n",
    "\n",
    "    # Ganho em memória\n",
    "    mem_svm = (N_sv * K) + N_sv + 1\n",
    "    mem_perceptron = K + 1\n",
    "\n",
    "    print(\"\\nGanho Computacional em Memória (nº de floats):\")\n",
    "    print(f\"  Memória SVM Original: {mem_svm}\")\n",
    "    print(f\"  Memória Perceptron: {mem_perceptron}\")\n",
    "\n",
    "    if N_sv > 0 and mem_perceptron > 0:\n",
    "        if mem_svm > mem_perceptron:\n",
    "             print(f\"  Redução de memória: Fator de ~{mem_svm / mem_perceptron:.2f}\")\n",
    "             print(\"  => Há um ganho em memória.\")\n",
    "        else:\n",
    "             print(\"  => O uso de memória é similar ou o perceptron requer mais (caso atípico para N_sv > 0).\")\n",
    "    elif N_sv == 0:\n",
    "        print(\"  => Sem vetores de suporte; análise de ganho não aplicável.\")\n",
    "    else:\n",
    "        print(\"  => Não foi possível calcular o fator de redução de memória.\")\n",
    "\n",
    "except FileNotFoundError as fnf_error:\n",
    "    print(f\"\\nERRO CRÍTICO: Arquivo não encontrado - {fnf_error}\")\n",
    "    print(\"Verifique se os arquivos 'dataset_train.txt' e 'dataset_test.txt' estão no mesmo diretório do script e se os nomes estão corretos.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOCORREU UM ERRO INESPERADO: {e}\")\n",
    "\n",
    "print(\"\\n--- Fim da Questão 6 ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de088259-31c7-4476-b498-5eeef68017f3",
   "metadata": {},
   "source": [
    "## Conclusões e Análise dos Resultados da Questão 6\n",
    "\n",
    "O código para a Questão 6 foi executado com sucesso, abrangendo o carregamento e normalização dos dados, o treinamento da SVM linear, a avaliação de seu desempenho e a análise do custo computacional em comparação com uma forma de perceptron.\n",
    "\n",
    "---\n",
    "### 1. Carregamento, Normalização e Treinamento da SVM\n",
    "\n",
    "* **Carregamento dos Dados:**\n",
    "    * Dataset de treino: 6 amostras, 2 features.\n",
    "    * Dataset de teste: 4 amostras, 2 features.\n",
    "    Os dados foram carregados corretamente, assumindo o formato de valores separados por vírgula.\n",
    "* **Normalização:** Os dados foram normalizados (média 0, variância 1) com base no conjunto de treino, e a mesma transformação foi aplicada ao conjunto de teste.\n",
    "* **Modelo SVM Linear (C=1):**\n",
    "    * A SVM foi treinada com sucesso.\n",
    "    * Número de vetores de suporte por classe: `[2 2]`.\n",
    "    * Total de vetores de suporte: **4**.\n",
    "\n",
    "---\n",
    "### 2. Desempenho do Modelo no Conjunto de Teste\n",
    "\n",
    "* **Acurácia:** **1.0000** (100%).\n",
    "    O modelo classificou perfeitamente todas as 4 amostras do conjunto de teste.\n",
    "* **Relatório de Classificação:**\n",
    "    * Precision, Recall e F1-score foram de 1.00 para ambas as classes (0.0 e 1.0).\n",
    "    Isso confirma o desempenho ideal do modelo no conjunto de teste fornecido. Para um dataset tão pequeno, a performance perfeita é possível, mas em cenários mais complexos, seria importante ter um conjunto de teste maior e mais diversificado.\n",
    "\n",
    "---\n",
    "### 3. Análise de Custo Computacional e Conversão para Perceptron\n",
    "\n",
    "A análise foi realizada para $K=2$ features e $N_{sv}=4$ vetores de suporte.\n",
    "\n",
    "* **Custo da SVM Original (por predição, usando vetores de suporte):**\n",
    "    * Multiplicações: 12\n",
    "    * Adições: 8\n",
    "* **Custo da Versão Perceptron ($w \\cdot z + b$, por predição):**\n",
    "    * Multiplicações: 2\n",
    "    * Adições: 2\n",
    "\n",
    "* **Ganho Computacional em Operações:**\n",
    "    * A SVM original (forma com vetores de suporte) realiza aproximadamente **6.00 vezes mais multiplicações** que o perceptron.\n",
    "    * A SVM original realiza aproximadamente **4.00 vezes mais adições** que o perceptron.\n",
    "    * **Conclusão:** Há um ganho substancial no número de operações ao utilizar a forma de perceptron para a predição, uma vez que o vetor de pesos $w$ já \"compilou\" a informação dos vetores de suporte.\n",
    "\n",
    "* **Ganho Computacional em Memória (número de floats a serem armazenados para predição):**\n",
    "    * Memória SVM Original (armazenando SVs, coeficientes duais, bias): 13 floats.\n",
    "    * Memória Perceptron (armazenando $w$, bias): 3 floats.\n",
    "    * A SVM original requer aproximadamente **4.33 vezes mais memória** que o perceptron.\n",
    "    * **Conclusão:** Há também um ganho significativo em memória, pois não é mais necessário armazenar todos os vetores de suporte individualmente.\n",
    "\n",
    "---\n",
    "**Considerações Finais da Questão 6:**\n",
    "Os resultados demonstram que, para uma SVM linear, sua representação como um perceptron ($w \\cdot z + b$) é muito mais eficiente para a fase de teste (predição) em termos de custo computacional (operações e memória) quando comparada à forma que explicitamente utiliza os vetores de suporte e coeficientes duais no cálculo da decisão. Essa eficiência é particularmente pronunciada quando o número de vetores de suporte ($N_{sv}$) é maior que 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4168d49-5a60-46d3-add4-d90a00519219",
   "metadata": {},
   "source": [
    "## Questão 7: Projeto de SVMs com Kernel Gaussiano (RBF)\n",
    "\n",
    "Esta questão foca no projeto de SVMs com kernel Gaussiano (também chamado de \"RBF\"). Utilizaremos o conjunto de validação para fazer o \"tuning\" (otimização) de dois hiperparâmetros: \"C\" (parâmetro de regularização) e \"gamma\" (parâmetro do kernel RBF).\n",
    "\n",
    "Os valores a serem avaliados são:\n",
    "* $C \\in \\{0.01, 1, 100\\}$\n",
    "* $\\text{gamma} \\in \\{0.5, 1\\}$\n",
    "\n",
    "Isso resultará em $3 \\times 2 = 6$ combinações de SVMs a serem treinadas e avaliadas.\n",
    "\n",
    "**Objetivos:**\n",
    "\n",
    "* **a) Treinamento e Validação:**\n",
    "    1.  Normalizar os dados de treino, validação e teste. O `scaler` deve ser ajustado apenas com os dados de treino.\n",
    "    2.  Treinar as 6 SVMs com o conjunto de treino normalizado, variando `C` e `gamma`.\n",
    "    3.  Observar o resultado (acurácia) de cada SVM no conjunto de validação normalizado.\n",
    "    4.  Indicar qual combinação de `C` e `gamma` apresenta a melhor performance no conjunto de validação. Esta será a \"SVM escolhida\".\n",
    "\n",
    "* **b) Descrição da SVM Escolhida:**\n",
    "    Para a SVM escolhida no item (a), descrever totalmente os parâmetros que compõem a sua fórmula final, indicando:\n",
    "    1.  O valor de `gamma` escolhido (e o `C` usado no treino).\n",
    "    2.  O número total de vetores de suporte (SVs) e o número por classe.\n",
    "    3.  Os índices dos vetores de suporte no conjunto de treino original.\n",
    "    4.  Os respectivos valores dos \"lambdas\" (coeficientes duais, `dual_coef_` no scikit-learn, que armazenam $y_i \\alpha_i$).\n",
    "    5.  O termo independente `b` (bias ou `intercept_`).\n",
    "\n",
    "* **c) Comparação do Score da Função de Decisão:**\n",
    "    Usando a SVM escolhida e os dois primeiros exemplos do conjunto de teste normalizado ($z_1$ e $z_2$):\n",
    "    1.  Calcular o score da função de decisão $f(z)$ para $z_1$ e $z_2$ usando o método `decision_function()` da classe SVM do scikit-learn.\n",
    "    2.  Calcular manualmente o score da função de decisão $f(z) = \\sum_{i \\in SVs} (y_i \\alpha_i) K(z, x_i) + b$ para $z_1$ e $z_2$, utilizando os parâmetros obtidos no item (b). O kernel RBF é $K(u,v) = \\exp(-\\text{gamma} ||u-v||^2)$.\n",
    "    3.  Comparar os resultados numéricos e buscar explicar eventuais discrepâncias (que geralmente se devem à precisão de ponto flutuante).\n",
    "\n",
    "A seguir, o código Python para realizar esses passos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51524114-0ba2-4624-ba0e-eebd2679c365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Carregando Datasets para Questão 7 ---\n",
      "  Dataset de treino carregado.\n",
      "  Dataset de validação carregado.\n",
      "  Dataset de teste carregado.\n",
      "Datasets carregados com sucesso!\n",
      "\n",
      "--- Iniciando Questão 7 (após carregamento de dados) ---\n",
      "\n",
      "--- a) Treinamento, Validação e Escolha da Melhor SVM ---\n",
      "\n",
      "Iniciando a otimização de hiperparâmetros (C e gamma) para SVM com kernel RBF...\n",
      "  C=0.01, gamma=0.5 -> Acurácia na Validação: 0.8750\n",
      "  C=0.01, gamma=1 -> Acurácia na Validação: 0.6250\n",
      "  C=1, gamma=0.5 -> Acurácia na Validação: 0.8750\n",
      "  C=1, gamma=1 -> Acurácia na Validação: 0.6250\n",
      "  C=100, gamma=0.5 -> Acurácia na Validação: 0.8750\n",
      "  C=100, gamma=1 -> Acurácia na Validação: 0.8750\n",
      "\n",
      "Melhor SVM encontrada no conjunto de validação:\n",
      "  Parâmetros: C=0.01, gamma=0.5\n",
      "  Acurácia na Validação: 0.8750\n",
      "\n",
      "--- b) Descrição Completa da SVM Escolhida ---\n",
      "b1) Parâmetros escolhidos do kernel (gamma): 0.5\n",
      "    (Hiperparâmetro de treino C: 0.01)\n",
      "b2) Número de vetores de suporte por classe: [3 3]\n",
      "    Número total de vetores de suporte: 6\n",
      "b3) Índices dos vetores de suporte no conjunto de treino original (primeiros 10, se houver): [0 1 2 3 4 5]\n",
      "b4) Coeficientes duais (lambda_n = y_n * alpha_n) (forma: (1, 6)):\n",
      "b5) Termo independente b (bias/intercept_): [-0.00363247]\n",
      "\n",
      "--- c) Comparação do Score da Função de Decisão ---\n",
      "\n",
      "Scores calculados pelo scikit-learn (decision_function()):\n",
      "  f(z1_norm): -0.01110064\n",
      "  f(z2_norm): -0.00858536\n",
      "\n",
      "Scores calculados manualmente:\n",
      "  f_manual(z1_norm): -0.01110064\n",
      "  f_manual(z2_norm): -0.00858536\n",
      "\n",
      "Comparação e Discrepâncias:\n",
      "  Discrepância absoluta para z1: 0.00e+00\n",
      "  Discrepância absoluta para z2: 3.47e-18\n",
      "  Os resultados são consistentes.\n",
      "\n",
      "--- Fim da Questão 7 ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Para o item (c), se quiser usar a função de distância euclidiana ao quadrado mais diretamente\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "# --- Carregando Datasets para Questão 7 ---\n",
    "print(\"--- Carregando Datasets para Questão 7 ---\")\n",
    "try:\n",
    "    # Carregar conjunto de treino\n",
    "    train_data = np.loadtxt('dataset_train.txt', delimiter=',')\n",
    "    X_train = train_data[:, :-1]\n",
    "    y_train = train_data[:, -1]\n",
    "    print(\"  Dataset de treino carregado.\")\n",
    "\n",
    "    # Carregar conjunto de validação\n",
    "    validation_data = np.loadtxt('dataset_validation.txt', delimiter=',') # Certifique-se que o nome do arquivo está correto\n",
    "    X_val = validation_data[:, :-1]\n",
    "    y_val = validation_data[:, -1]\n",
    "    print(\"  Dataset de validação carregado.\")\n",
    "\n",
    "    # Carregar conjunto de teste\n",
    "    test_data = np.loadtxt('dataset_test.txt', delimiter=',')\n",
    "    X_test = test_data[:, :-1]\n",
    "    y_test = test_data[:, -1]\n",
    "    print(\"  Dataset de teste carregado.\")\n",
    "    print(\"Datasets carregados com sucesso!\")\n",
    "\n",
    "except FileNotFoundError as fnf_error:\n",
    "    print(f\"ERRO CRÍTICO: Arquivo não encontrado - {fnf_error}\")\n",
    "    print(\"Verifique se os arquivos de dataset ('dataset_train.txt', 'dataset_validation.txt', 'dataset_test.txt') estão no diretório correto, com os nomes corretos e usando ',' como delimitador.\")\n",
    "    # Interrompe a execução se os arquivos não forem encontrados, pois o resto do código depende deles.\n",
    "    # Em um notebook, você pode querer remover o exit() e apenas lidar com o erro na célula.\n",
    "    # exit()\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro ao carregar os datasets: {e}\")\n",
    "    # exit()\n",
    "\n",
    "\n",
    "print(\"\\n--- Iniciando Questão 7 (após carregamento de dados) ---\")\n",
    "\n",
    "# Verifica se as variáveis X_train, X_val, X_test foram definidas antes de prosseguir\n",
    "if 'X_train' in locals() and 'y_train' in locals() and \\\n",
    "   'X_val' in locals() and 'y_val' in locals() and \\\n",
    "   'X_test' in locals() and 'y_test' in locals():\n",
    "\n",
    "    # --- a) Treinamento, Validação e Escolha da Melhor SVM ---\n",
    "    print(\"\\n--- a) Treinamento, Validação e Escolha da Melhor SVM ---\")\n",
    "\n",
    "    # Normalização dos dados (ajustar no treino, aplicar na validação e teste)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_norm = scaler.fit_transform(X_train)\n",
    "    X_val_norm = scaler.transform(X_val) # Agora X_val deve estar definido\n",
    "    X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "    param_C_values = [0.01, 1, 100]\n",
    "    param_gamma_values = [0.5, 1]\n",
    "\n",
    "    best_accuracy_val = -1\n",
    "    best_params = {}\n",
    "    best_svm_model = None\n",
    "\n",
    "    print(\"\\nIniciando a otimização de hiperparâmetros (C e gamma) para SVM com kernel RBF...\")\n",
    "\n",
    "    for C_val in param_C_values:\n",
    "        for gamma_val in param_gamma_values:\n",
    "            current_svm = SVC(kernel='rbf', C=C_val, gamma=gamma_val, probability=False)\n",
    "            current_svm.fit(X_train_norm, y_train)\n",
    "            accuracy_val = current_svm.score(X_val_norm, y_val)\n",
    "            print(f\"  C={C_val}, gamma={gamma_val} -> Acurácia na Validação: {accuracy_val:.4f}\")\n",
    "            if accuracy_val > best_accuracy_val:\n",
    "                best_accuracy_val = accuracy_val\n",
    "                best_params = {'C': C_val, 'gamma': gamma_val}\n",
    "                best_svm_model = current_svm\n",
    "\n",
    "    print(f\"\\nMelhor SVM encontrada no conjunto de validação:\")\n",
    "    if best_svm_model:\n",
    "        print(f\"  Parâmetros: C={best_params.get('C')}, gamma={best_params.get('gamma')}\")\n",
    "        print(f\"  Acurácia na Validação: {best_accuracy_val:.4f}\")\n",
    "    else:\n",
    "        print(\"  Nenhum modelo foi treinado com sucesso ou avaliado.\")\n",
    "\n",
    "    # --- b) Descrição Completa da SVM Escolhida ---\n",
    "    # (O restante do código para os itens b e c segue aqui, como no exemplo anterior)\n",
    "    # Certifique-se que 'best_svm_model' foi definido antes de prosseguir para os itens b e c.\n",
    "\n",
    "    if best_svm_model:\n",
    "        print(\"\\n--- b) Descrição Completa da SVM Escolhida ---\")\n",
    "        chosen_C = best_svm_model.C\n",
    "        chosen_gamma = best_svm_model.gamma\n",
    "        num_svs_per_class = best_svm_model.n_support_\n",
    "        total_svs = np.sum(num_svs_per_class)\n",
    "        indices_svs = best_svm_model.support_\n",
    "        actual_support_vectors = best_svm_model.support_vectors_\n",
    "        dual_coefficients = best_svm_model.dual_coef_\n",
    "        bias_b = best_svm_model.intercept_\n",
    "\n",
    "        print(f\"b1) Parâmetros escolhidos do kernel (gamma): {chosen_gamma}\")\n",
    "        print(f\"    (Hiperparâmetro de treino C: {chosen_C})\")\n",
    "        print(f\"b2) Número de vetores de suporte por classe: {num_svs_per_class}\")\n",
    "        print(f\"    Número total de vetores de suporte: {total_svs}\")\n",
    "        print(f\"b3) Índices dos vetores de suporte no conjunto de treino original (primeiros 10, se houver): {indices_svs[:10]}\")\n",
    "        print(f\"b4) Coeficientes duais (lambda_n = y_n * alpha_n) (forma: {dual_coefficients.shape}):\")\n",
    "        print(f\"b5) Termo independente b (bias/intercept_): {bias_b}\")\n",
    "\n",
    "        # --- c) Comparação do Score da Função de Decisão ---\n",
    "        print(\"\\n--- c) Comparação do Score da Função de Decisão ---\")\n",
    "        if X_test_norm.shape[0] >= 2:\n",
    "            z1_norm = X_test_norm[0:1]\n",
    "            z2_norm = X_test_norm[1:2]\n",
    "\n",
    "            score_sklearn_z1 = best_svm_model.decision_function(z1_norm)[0]\n",
    "            score_sklearn_z2 = best_svm_model.decision_function(z2_norm)[0]\n",
    "            \n",
    "            print(f\"\\nScores calculados pelo scikit-learn (decision_function()):\")\n",
    "            print(f\"  f(z1_norm): {score_sklearn_z1:.8f}\")\n",
    "            print(f\"  f(z2_norm): {score_sklearn_z2:.8f}\")\n",
    "\n",
    "            def rbf_kernel_manual(vec1, vec2, gamma_val):\n",
    "                squared_norm = euclidean_distances(vec1.reshape(1, -1), vec2.reshape(1, -1))[0,0]**2\n",
    "                return np.exp(-gamma_val * squared_norm)\n",
    "\n",
    "            def manual_decision_function(sample_z, support_vecs_array, dual_coeffs_flat_array, intercept_val, gamma_val):\n",
    "                score = 0.0\n",
    "                sample_z_flat = sample_z.flatten()\n",
    "                for i in range(support_vecs_array.shape[0]):\n",
    "                    kernel_val = rbf_kernel_manual(sample_z_flat, support_vecs_array[i].flatten(), gamma_val)\n",
    "                    score += dual_coeffs_flat_array[i] * kernel_val\n",
    "                score += intercept_val\n",
    "                return score\n",
    "\n",
    "            manual_score_z1 = manual_decision_function(z1_norm, actual_support_vectors, dual_coefficients[0], bias_b[0], chosen_gamma)\n",
    "            manual_score_z2 = manual_decision_function(z2_norm, actual_support_vectors, dual_coefficients[0], bias_b[0], chosen_gamma)\n",
    "            \n",
    "            print(f\"\\nScores calculados manualmente:\")\n",
    "            print(f\"  f_manual(z1_norm): {manual_score_z1:.8f}\")\n",
    "            print(f\"  f_manual(z2_norm): {manual_score_z2:.8f}\")\n",
    "            \n",
    "            discrepancy_z1 = np.abs(score_sklearn_z1 - manual_score_z1)\n",
    "            discrepancy_z2 = np.abs(score_sklearn_z2 - manual_score_z2)\n",
    "            print(f\"\\nComparação e Discrepâncias:\")\n",
    "            print(f\"  Discrepância absoluta para z1: {discrepancy_z1:.2e}\")\n",
    "            print(f\"  Discrepância absoluta para z2: {discrepancy_z2:.2e}\")\n",
    "            \n",
    "            threshold = 1e-6 \n",
    "            if discrepancy_z1 < threshold and discrepancy_z2 < threshold:\n",
    "                print(\"  Os resultados são consistentes.\")\n",
    "            else:\n",
    "                print(\"  Há discrepâncias notáveis.\")\n",
    "        else:\n",
    "            print(\"  O conjunto de teste não possui pelo menos dois exemplos.\")\n",
    "    else:\n",
    "        print(\"  Nenhuma SVM foi escolhida no item (a). Itens (b) e (c) não podem ser executados.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nERRO: Datasets não foram carregados corretamente. O restante da Questão 7 não pode ser executado.\")\n",
    "\n",
    "print(\"\\n--- Fim da Questão 7 ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbab32a-ce99-4c7b-a968-dcce0ac17643",
   "metadata": {},
   "source": [
    "## Conclusões e Análise dos Resultados da Questão 7\n",
    "\n",
    "O código para a Questão 7 foi executado com sucesso, realizando o treinamento e a avaliação de múltiplas SVMs com kernel RBF, a seleção do melhor modelo com base no conjunto de validação, a descrição detalhada dos seus parâmetros e a verificação da função de decisão.\n",
    "\n",
    "---\n",
    "### a) Resultado do Treinamento e Validação\n",
    "\n",
    "A otimização dos hiperparâmetros `C` e `gamma` no conjunto de validação forneceu os seguintes resultados principais:\n",
    "\n",
    "* **Combinações Avaliadas:**\n",
    "    * C=0.01, gamma=0.5 $\\rightarrow$ Acurácia na Validação: 0.8750\n",
    "    * C=0.01, gamma=1 $\\rightarrow$ Acurácia na Validação: 0.6250\n",
    "    * C=1, gamma=0.5 $\\rightarrow$ Acurácia na Validação: 0.8750\n",
    "    * C=1, gamma=1 $\\rightarrow$ Acurácia na Validação: 0.6250\n",
    "    * C=100, gamma=0.5 $\\rightarrow$ Acurácia na Validação: 0.8750\n",
    "    * C=100, gamma=1 $\\rightarrow$ Acurácia na Validação: 0.8750\n",
    "\n",
    "* **Melhor SVM Escolhida (com base na primeira ocorrência da maior acurácia):**\n",
    "    * **Parâmetros**: C=0.01, gamma=0.5\n",
    "    * **Acurácia na Validação**: 0.8750\n",
    "\n",
    "Observou-se que múltiplas combinações de hiperparâmetros resultaram na mesma acurácia máxima de validação (0.8750). A seleção de C=0.01 e gamma=0.5 corresponde à primeira dessas combinações encontradas durante a busca. Modelos com menor `C` tendem a ter margens maiores e podem ser considerados menos complexos, o que pode ser um critério de desempate desejável.\n",
    "\n",
    "---\n",
    "### b) Descrição Detalhada da SVM Escolhida (C=0.01, gamma=0.5)\n",
    "\n",
    "Os parâmetros da SVM que obteve a melhor performance no conjunto de validação são:\n",
    "\n",
    "1.  **Parâmetros do Kernel e Treino:**\n",
    "    * `gamma`: 0.5\n",
    "    * `C` (usado no treino): 0.01\n",
    "2.  **Vetores de Suporte (SVs):**\n",
    "    * Número por classe: `[3 3]` (3 para a primeira classe, 3 para a segunda).\n",
    "    * Número total: 6.\n",
    "3.  **Índices dos SVs no Conjunto de Treino:** `[0 1 2 3 4 5]`. Isso indica que, para este dataset e configuração, todos os 6 exemplos do conjunto de treino se tornaram vetores de suporte.\n",
    "4.  **Coeficientes Duais ($\\lambda_n = y_n \\alpha_i$):**\n",
    "    * Possuem a forma (1, 6), correspondendo a um coeficiente para cada um dos 6 vetores de suporte.\n",
    "5.  **Termo Independente (Bias $b$):**\n",
    "    * `intercept_`: Aproximadamente `[-0.00363247]`.\n",
    "\n",
    "Esses parâmetros definem completamente a função de decisão da SVM escolhida.\n",
    "\n",
    "---\n",
    "### c) Comparação do Score da Função de Decisão\n",
    "\n",
    "A verificação da função de decisão para os dois primeiros exemplos do conjunto de teste (`z1_norm`, `z2_norm`) produziu os seguintes resultados:\n",
    "\n",
    "* **Scores via `decision_function()` do scikit-learn:**\n",
    "    * $f(z1_{norm}) \\approx -0.01110064$\n",
    "    * $f(z2_{norm}) \\approx -0.00858536$\n",
    "\n",
    "* **Scores calculados manualmente (usando os parâmetros de (b)):**\n",
    "    * $f_{manual}(z1_{norm}) \\approx -0.01110064$\n",
    "    * $f_{manual}(z2_{norm}) \\approx -0.00858536$\n",
    "\n",
    "* **Discrepâncias Absolutas:**\n",
    "    * Para $z1_{norm}$: $0.00 \\times 10^0$ (essencialmente zero).\n",
    "    * Para $z2_{norm}$: $3.47 \\times 10^{-18}$ (um valor extremamente pequeno, atribuível à precisão de ponto flutuante).\n",
    "\n",
    "**Conclusão da Comparação:**\n",
    "Os resultados da função de decisão calculada manualmente e os obtidos pela função `decision_function()` do scikit-learn são virtualmente idênticos. As minúsculas discrepâncias observadas estão bem dentro da margem esperada para erros de precisão numérica em cálculos de ponto flutuante. Isso valida a correção da extração dos parâmetros do modelo e da implementação manual da função de decisão e do kernel RBF.\n",
    "\n",
    "---\n",
    "**Considerações Finais da Questão 7:**\n",
    "O processo de tuning de hiperparâmetros permitiu identificar uma configuração de SVM (C=0.01, gamma=0.5) que obteve um bom desempenho no conjunto de validação. A análise detalhada dos parâmetros desta SVM e a verificação da sua função de decisão confirmam o entendimento do modelo treinado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
